{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/conda/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "import random\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Dense, Reshape, merge, Dot, Concatenate\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.sequence import skipgrams\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('zinc_4325992_wash.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, SVG\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "\n",
    "def show(mol,molSize=(475,175),kekulize=True):\n",
    "    mc = Chem.Mol(mol.ToBinary())\n",
    "    if kekulize:\n",
    "        try:\n",
    "            Chem.Kekulize(mc)\n",
    "        except:\n",
    "            mc = Chem.Mol(mol.ToBinary())\n",
    "    assert mc.GetNumConformers() > 0\n",
    "    drawer = rdMolDraw2D.MolDraw2DSVG(molSize[0],molSize[1])\n",
    "    drawer.DrawMolecule(mc)\n",
    "    drawer.FinishDrawing()\n",
    "    svg = drawer.GetDrawingText()\n",
    "    display(SVG(svg.replace('svg:','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(df)\n",
    "print(\"numbers: \", length)\n",
    "smiles = df[\"mol\"]\n",
    "smileslist = list(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validatedsmiles = []\n",
    "\n",
    "notvalidated = 0\n",
    "for smile in smileslist:\n",
    "    m = Chem.MolFromSmiles(smile)\n",
    "    if m is None:\n",
    "        notvalidated += 1\n",
    "        if notvalidated % 10000 == 0:\n",
    "            #print(\"not validated:\", notvalidated)\n",
    "            print(\"not validated:\", smile)\n",
    "    else:\n",
    "        validatedsmiles.append(smile)\n",
    "print(\"non validated smiles:\", notvalidated)\n",
    "print(\"not validate smiles rate:\", notvalidated/length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '\\n'.join(validatedsmiles)\n",
    "#data= data.lower().strip()\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('There are %d total characters and %d unique characters in your data.' % (data_size, vocab_size))\n",
    "print(\"first smiles: \", smileslist[0])\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lensmile = [len(x) for x in validatedsmiles]\n",
    "\n",
    "print(\"minimum:\", np.min(lensmile))\n",
    "print(\"mean:\", np.mean(lensmile))\n",
    "print(\"std:\", np.std(lensmile))\n",
    "print(\"maximum:\",np.max(lensmile))\n",
    "\n",
    "plt.hist(lensmile, bins=500, facecolor='r',histtype='stepfilled')\n",
    "#plt.plot(x,y,color='b')   \n",
    " \n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Number of Lenth')\n",
    "plt.title('Distribution of Smiles Length')\n",
    "plt.savefig('histogramDescription.pdf', format='pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validatedsmiles[np.argmin(lensmile)])\n",
    "m = Chem.MolFromSmiles(validatedsmiles[np.argmin(lensmile)])\n",
    "AllChem.Compute2DCoords(m)\n",
    "show(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validatedsmiles[np.argmax(lensmile)])\n",
    "m = Chem.MolFromSmiles(validatedsmiles[np.argmax(lensmile)])\n",
    "AllChem.Compute2DCoords(m)\n",
    "show(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(validatedsmiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "char_to_ix = { ch:i for i,ch in enumerate(sorted(chars)) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(sorted(chars)) }\n",
    "print(ix_to_char)\n",
    "print(char_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validatedsmiles_pd = pd.DataFrame(validatedsmiles, columns=['smiles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validatedsmiles_pd.to_csv('validatedsmiles_pd.csv', encoding='utf-8', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read validated smils from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = pd.read_csv('validatedsmiles_pd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lensmile = [len(x) for x in smiles['smiles']]\n",
    "\n",
    "print(\"minimum:\", np.min(lensmile))\n",
    "print(\"mean:\", np.mean(lensmile))\n",
    "print(\"std:\", np.std(lensmile))\n",
    "print(\"maximum:\",np.max(lensmile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(lensmile)\n",
    "mu\n",
    "\n",
    "sigma = np.std(lensmile)\n",
    "sigma\n",
    "\n",
    "interval = stats.norm.interval(0.98, mu, sigma) \n",
    "interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add lens to data frame\n",
    "\n",
    "#smiles['lens'] = pd.Series(lensmile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter smiles only contains len(smiles) <= 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalsmiles = smiles[(lensmile >= interval[0]) & (lensmile <= interval[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalsmiles.to_csv('finalsmiles_pd.csv', encoding='utf-8', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Smiles to Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read smiles from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>lens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S([C@@H](C(=O)N1CCCC1)C)C1=NC(=O)c2c(N1)ccc(F)c2</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O=C(NCC1(Cn2nccc2)CC1)c1nnc([O-])c2c1cccc2</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S(=O)(=O)(CCN[C@@H]([C@H](C)n1nccc1)C)c1ccccc1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S(CCC(=O)N1CCNCC1)Cc1ccc(C)cc1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fc1c(CNC2CCN(C(=O)c3cocc3)CC2)c(F)ccc1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             smiles  lens\n",
       "0  S([C@@H](C(=O)N1CCCC1)C)C1=NC(=O)c2c(N1)ccc(F)c2    48\n",
       "1        O=C(NCC1(Cn2nccc2)CC1)c1nnc([O-])c2c1cccc2    42\n",
       "2    S(=O)(=O)(CCN[C@@H]([C@H](C)n1nccc1)C)c1ccccc1    46\n",
       "3                    S(CCC(=O)N1CCNCC1)Cc1ccc(C)cc1    30\n",
       "4            Fc1c(CNC2CCN(C(=O)c3cocc3)CC2)c(F)ccc1    38"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_pd = pd.read_csv('finalsmiles_pd.csv')\n",
    "smiles_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2883247, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_pd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Keras Tokenizer by Char "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer(lower=False, char_level=True, split='')\n",
    "t.fit_on_texts(data)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "print(\"vocab size: \" + str(vocab_size))\n",
    "#word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')\n",
    "\n",
    "word_to_index = t.word_index\n",
    "print(word_to_index)\n",
    "\n",
    "index_to_word = {v: k for k, v in word_to_index.items()}\n",
    "\n",
    "encoded_X = t.texts_to_sequences(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_X[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smiles to Char list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smileslist = smiles_pd['smiles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datawithnextline = '\\n'.join(smileslist)\n",
    "data = ''.join(smileslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chars = set(data)\n",
    "def precess_smiles_as_charlist(data):\n",
    "\n",
    "    allchars = []\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    while i < len(data):\n",
    "\n",
    "        if data[i] == 'B' and data[i+1] == 'r':\n",
    "            allchars.append('Br')\n",
    "            i += 1\n",
    "\n",
    "        elif data[i] == 'C' and data[i+1] == 'l':\n",
    "            allchars.append('Cl')\n",
    "            i += 1\n",
    "\n",
    "        else:    \n",
    "            allchars.append(data[i])\n",
    "\n",
    "        i += 1\n",
    "    \n",
    "    return allchars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## smiles to char list without '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "allchars = precess_smiles_as_charlist(data)\n",
    "chars = set(allchars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## smiles to char list with '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcharswithn = precess_smiles_as_charlist(datawithnextline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicts for char_to_index and index_to_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Atom: C H O N S P F Cl Br I B c o n s p\n",
    "* bond: . = # : $\n",
    "* electonric: + -\n",
    "* @ \\ /\n",
    "* () []\n",
    "* 1 2 3 4 5 6 7 8 9 %\n",
    "* Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '#', 1: '(', 2: ')', 3: '+', 4: '-', 5: '/', 6: '0', 7: '1', 8: '2', 9: '3', 10: '4', 11: '5', 12: '6', 13: '=', 14: '@', 15: 'Br', 16: 'C', 17: 'Cl', 18: 'F', 19: 'H', 20: 'I', 21: 'N', 22: 'O', 23: 'P', 24: 'S', 25: '[', 26: '\\\\', 27: ']', 28: 'c', 29: 'n', 30: 'o', 31: 'p', 32: 's'}\n"
     ]
    }
   ],
   "source": [
    "char_to_ix = { ch:i for i,ch in enumerate(sorted(chars)) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(sorted(chars)) }\n",
    "print(ix_to_char)\n",
    "#print(char_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dont have elements: \n",
    ".  : $ 7 8 9 Other , where '\\\\\\' is '\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use char_to_ix to indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsmilesindexlist = []\n",
    "smileindexlist = []\n",
    "\n",
    "for char in allcharswithn:\n",
    "    \n",
    "    if char != '\\n':\n",
    "        smileindexlist.append(char_to_ix[char])\n",
    "    else:\n",
    "        allsmilesindexlist.append(smileindexlist)\n",
    "        smileindexlist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2883246"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allsmilesindexlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24,\n",
       " 1,\n",
       " 25,\n",
       " 16,\n",
       " 14,\n",
       " 14,\n",
       " 19,\n",
       " 27,\n",
       " 1,\n",
       " 16,\n",
       " 1,\n",
       " 13,\n",
       " 22,\n",
       " 2,\n",
       " 21,\n",
       " 7,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 7,\n",
       " 2,\n",
       " 16,\n",
       " 2,\n",
       " 16,\n",
       " 7,\n",
       " 13,\n",
       " 21,\n",
       " 16,\n",
       " 1,\n",
       " 13,\n",
       " 22,\n",
       " 2,\n",
       " 28,\n",
       " 8,\n",
       " 28,\n",
       " 1,\n",
       " 21,\n",
       " 7,\n",
       " 2,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 1,\n",
       " 18,\n",
       " 2,\n",
       " 28,\n",
       " 8]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allsmilesindexlist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 8\n",
    "vector_dim = 200\n",
    "vocab_size = len(char_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_couples, s_labels = skipgrams(allsmilesindexlist[0], vocab_size, window_size=window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip-gram (only 50000 molecualrs, require more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process in smile: 10000\n",
      "process in smile: 20000\n",
      "process in smile: 30000\n",
      "process in smile: 40000\n",
      "process in smile: 50000\n"
     ]
    }
   ],
   "source": [
    "#sampling_table = sequence.make_sampling_table(vocab_size)\n",
    "couples = []\n",
    "labels = []\n",
    "\n",
    "i = 0\n",
    "for smileindex in allsmilesindexlist:\n",
    "   \n",
    "    s_couples, s_labels = skipgrams(smileindex, vocab_size, negative_samples = 1, window_size=window_size)\n",
    "   \n",
    "    couples += s_couples\n",
    "    labels += s_labels\n",
    "    \n",
    "    i += 1\n",
    "    if i % 10000 == 0:\n",
    "        print('process in smile:', i)\n",
    "        \n",
    "    if i == 50000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59698664"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(couples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59698664"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 12],\n",
       " [14, 23],\n",
       " [28, 18],\n",
       " [14, 14],\n",
       " [16, 1],\n",
       " [16, 25],\n",
       " [28, 1],\n",
       " [2, 1],\n",
       " [16, 13],\n",
       " [13, 11],\n",
       " [7, 2],\n",
       " [7, 14],\n",
       " [14, 19],\n",
       " [21, 8],\n",
       " [16, 25],\n",
       " [13, 28],\n",
       " [1, 14],\n",
       " [7, 2],\n",
       " [7, 14],\n",
       " [16, 10],\n",
       " [2, 12],\n",
       " [28, 2],\n",
       " [18, 28],\n",
       " [28, 21],\n",
       " [1, 16],\n",
       " [22, 12],\n",
       " [2, 6],\n",
       " [2, 16],\n",
       " [2, 21],\n",
       " [2, 22],\n",
       " [16, 13],\n",
       " [27, 16],\n",
       " [14, 15],\n",
       " [28, 32],\n",
       " [8, 19],\n",
       " [13, 16],\n",
       " [13, 2],\n",
       " [2, 7],\n",
       " [21, 4],\n",
       " [28, 21],\n",
       " [16, 7],\n",
       " [28, 8],\n",
       " [2, 25],\n",
       " [27, 22],\n",
       " [13, 13],\n",
       " [21, 20],\n",
       " [2, 22],\n",
       " [7, 7],\n",
       " [18, 22],\n",
       " [8, 13],\n",
       " [16, 15],\n",
       " [22, 12],\n",
       " [16, 8],\n",
       " [28, 7],\n",
       " [13, 28],\n",
       " [28, 28],\n",
       " [21, 30],\n",
       " [1, 2],\n",
       " [28, 22],\n",
       " [27, 24],\n",
       " [1, 14],\n",
       " [27, 12],\n",
       " [28, 18],\n",
       " [1, 18],\n",
       " [14, 22],\n",
       " [13, 22],\n",
       " [28, 10],\n",
       " [28, 28],\n",
       " [21, 24],\n",
       " [16, 28],\n",
       " [28, 8],\n",
       " [7, 28],\n",
       " [2, 32],\n",
       " [28, 28],\n",
       " [13, 3],\n",
       " [1, 14],\n",
       " [28, 28],\n",
       " [25, 24],\n",
       " [22, 21],\n",
       " [24, 27],\n",
       " [14, 5],\n",
       " [16, 21],\n",
       " [21, 26],\n",
       " [25, 3],\n",
       " [28, 26],\n",
       " [28, 5],\n",
       " [16, 16],\n",
       " [1, 2],\n",
       " [16, 32],\n",
       " [1, 19],\n",
       " [16, 1],\n",
       " [1, 12],\n",
       " [27, 7],\n",
       " [1, 13],\n",
       " [16, 2],\n",
       " [22, 22],\n",
       " [13, 21],\n",
       " [2, 27],\n",
       " [16, 30],\n",
       " [22, 5]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "couples[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_target, word_context = zip(*couples)\n",
    "word_target = np.array(word_target, dtype=\"int32\")\n",
    "word_context = np.array(word_context, dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59698664\n",
      "59698664\n",
      "[ 2 14 28 14 16 16 28  2 16 13] [12 23 18 14  1 25  1  1 13 11] [0, 0, 0, 0, 1, 0, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(len(word_target))\n",
    "print(len(word_context))\n",
    "print(word_target[:10], word_context[:10], labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Skipgram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 200)       6600        input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 400)       0           embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 400)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            401         reshape_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,001\n",
      "Trainable params: 7,001\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/conda/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "# create some input variables\n",
    "input_target = Input((1,))\n",
    "input_context = Input((1,))\n",
    "\n",
    "## embedding layer\n",
    "embedding = Embedding(vocab_size, vector_dim, input_length=1, name='embedding')\n",
    "\n",
    "## target\n",
    "target = embedding(input_target)\n",
    "\n",
    "## context\n",
    "context = embedding(input_context)\n",
    "\n",
    "## merge context and target\n",
    "dot_product = Concatenate(axis=2)([target, context])\n",
    "dot_product = Reshape((400, ))(dot_product)\n",
    "\n",
    "## predict\n",
    "output = Dense(1, activation='sigmoid')(dot_product)\n",
    "\n",
    "model = Model(input=[input_target, input_context], output=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 1, 200)            6600      \n",
      "=================================================================\n",
      "Total params: 6,600\n",
      "Trainable params: 6,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/conda/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"em...)`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "input_molecular = Input((1,))\n",
    "\n",
    "embeddedMolecular = embedding(input_molecular)\n",
    "\n",
    "embedding_model = Model(input=input_molecular, output=embeddedMolecular)\n",
    "\n",
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainning (Require more epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "59698664/59698664 [==============================] - 498s 8us/step - loss: 0.4632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x334f630f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = [word_target, word_context], y = labels, epochs = 1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model.save('mole2vec-skipgram.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/conda/anaconda3/lib/python3.6/site-packages/keras/models.py:282: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "embedding_model = load_model('mole2vec-skipgram.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(u, v):\n",
    "    \"\"\"\n",
    "    Cosine similarity reflects the degree of similariy between u and v\n",
    "        \n",
    "    Arguments:\n",
    "        u -- a word vector of shape (n,)          \n",
    "        v -- a word vector of shape (n,)\n",
    "\n",
    "    Returns:\n",
    "        cosine_similarity -- the cosine similarity between u and v defined by the formula above.\n",
    "    \"\"\"\n",
    "    \n",
    "    distance = 0.0\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Compute the dot product between u and v (≈1 line)\n",
    "    dot = np.sum(u*v)\n",
    "    # Compute the L2 norm of u (≈1 line)\n",
    "    norm_u = np.sqrt(np.sum(np.square(u)))   \n",
    "    # Compute the L2 norm of v (≈1 line)\n",
    "    norm_v = np.sqrt(np.sum(np.square(v)))\n",
    "    # Compute the cosine similarity defined by formula (1) (≈1 line)\n",
    "    cosine_similarity = dot / (norm_u*norm_v)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.022250967"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = embedding_model.predict([char_to_ix['(']]) -  embedding_model.predict([char_to_ix[')']])\n",
    "s2 = embedding_model.predict([char_to_ix['[']]) -  embedding_model.predict([char_to_ix[']']])\n",
    "\n",
    "cosine_similarity(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 7.14578703e-02, -3.98030207e-02,  5.57898581e-02,\n",
       "          2.50560809e-02, -3.30043361e-02, -1.08692139e-01,\n",
       "          6.14518039e-02, -6.20625168e-02, -2.32791994e-03,\n",
       "         -4.69901003e-02,  9.74946171e-02, -2.63790395e-02,\n",
       "         -5.48885670e-03, -2.37427279e-03, -1.07383849e-02,\n",
       "          3.64497080e-02,  4.25537936e-02,  1.39434161e-02,\n",
       "          1.32589504e-01,  1.78124346e-02,  8.45811982e-03,\n",
       "          9.87131894e-02, -1.10381786e-02,  3.94414179e-02,\n",
       "         -2.99292728e-02,  1.76506913e+00, -1.74931195e-02,\n",
       "         -2.59747487e-02, -8.26530978e-02, -1.30458577e-02,\n",
       "          7.19384775e-02, -7.52303526e-02, -9.00663063e-02,\n",
       "          8.07701051e-02,  8.69659148e-03, -4.14740667e-02,\n",
       "         -1.18514530e-01, -1.65126529e-02, -1.80607289e-02,\n",
       "          6.97746575e-02,  2.34687328e-01, -8.18871409e-02,\n",
       "          1.91780627e+00,  3.13647762e-02, -3.44711915e-02,\n",
       "          6.19419180e-02,  1.51685387e-01, -2.41593383e-02,\n",
       "         -9.37212445e-03, -8.78912061e-02,  1.55768413e-02,\n",
       "         -6.30281195e-02,  2.24917736e-02, -1.34895742e-01,\n",
       "          2.44767405e-02, -6.15934357e-02, -1.08147994e-01,\n",
       "         -3.80805433e-02, -1.03174455e-01,  4.34072465e-02,\n",
       "         -4.44658985e-03, -1.38783708e-01,  9.13587585e-02,\n",
       "         -2.60727610e-02,  1.63111594e-02, -1.15864752e-02,\n",
       "         -5.52540645e-02, -7.84692168e-03,  1.09288827e-01,\n",
       "          5.41588590e-02, -7.56440777e-03, -7.20335767e-02,\n",
       "         -1.58003774e-02,  1.13533652e+00, -3.92261408e-02,\n",
       "          5.94870411e-02,  3.46005000e-02,  1.33156493e-01,\n",
       "          7.56446719e-02,  4.29619625e-02,  1.60229668e-01,\n",
       "         -3.78311351e-02, -6.59475327e-02,  1.29808635e-01,\n",
       "          5.28946817e-02,  2.78507713e-02, -3.23859937e-02,\n",
       "         -9.24012735e-02, -7.35446811e-02,  9.08786505e-02,\n",
       "          8.44441876e-02, -1.45086600e-02,  5.28185144e-02,\n",
       "          1.39744170e-02, -6.34892806e-02, -9.34141129e-03,\n",
       "          7.69775212e-02, -5.59221618e-02, -1.75759852e+00,\n",
       "         -4.85713221e-02,  9.92845073e-02, -8.66765231e-02,\n",
       "         -2.80443560e-02,  8.94236416e-02, -1.31117746e-01,\n",
       "          1.74640268e-02,  2.89454847e-03,  3.34587730e-02,\n",
       "          1.92836877e-02,  9.72105324e-01,  1.38179436e-01,\n",
       "         -3.14816348e-02, -3.86807173e-02, -1.99222453e-02,\n",
       "          1.00691944e-01, -7.35429972e-02, -1.29804745e-01,\n",
       "         -8.21163505e-02, -1.15104064e-01,  1.56832288e-03,\n",
       "          1.42326280e-01, -1.16484120e-01, -3.65631445e-03,\n",
       "          9.76326130e-03,  5.56453541e-02,  8.94723088e-03,\n",
       "          6.52645752e-02,  3.70973088e-02,  5.53826522e-03,\n",
       "         -2.84962282e-02,  1.10170627e-02,  2.65346393e-02,\n",
       "         -8.40277374e-02, -1.69053125e+00,  2.63024885e-02,\n",
       "          1.43452408e-02,  7.53082857e-02,  9.04271156e-02,\n",
       "          2.30254475e-02, -1.69740282e-02,  5.41400164e-02,\n",
       "          7.44282082e-02, -3.64077426e-02,  9.24143940e-02,\n",
       "         -3.17418613e-02, -7.31962547e-02,  5.72880134e-02,\n",
       "          1.04437970e-01,  7.60920644e-02, -8.79379958e-02,\n",
       "         -2.33267043e-02, -6.43515140e-02,  1.97939132e-03,\n",
       "          1.15182392e-01,  9.96142402e-02, -1.29568860e-01,\n",
       "         -1.07490942e-01, -4.63220291e-03,  2.78403070e-02,\n",
       "         -1.24134153e-01,  3.69129777e-02, -1.41766027e-03,\n",
       "         -5.06409667e-02, -2.02872660e-02,  8.81839618e-02,\n",
       "          9.83638987e-02,  1.67233739e-02,  8.55675712e-02,\n",
       "         -2.72603016e-02, -5.66160381e-02,  8.11223406e-03,\n",
       "          1.01704776e-01,  4.79058884e-02,  7.44080357e-03,\n",
       "         -2.42950842e-02,  3.02188541e-03,  3.04369330e-02,\n",
       "          3.15635167e-02, -1.00469001e-01,  1.78166088e-02,\n",
       "          8.87587517e-02, -6.67984504e-03, -8.17265734e-02,\n",
       "         -9.96829867e-02, -5.11355698e-02, -5.37044182e-02,\n",
       "          1.04417279e-01, -9.60258767e-02,  2.50102673e-02,\n",
       "         -4.57299575e-02, -2.74828747e-02,  1.33017832e-02,\n",
       "         -9.57937073e-03,  7.01192170e-02, -6.52118474e-02,\n",
       "         -7.25500062e-02,  1.17693715e-01,  1.63440213e-01,\n",
       "          1.24799341e-01, -3.11995950e-02]]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.predict([char_to_ix['Cl']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "1dYg0",
   "launcher_item_id": "MLhxP"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
